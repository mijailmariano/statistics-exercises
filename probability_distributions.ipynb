{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A bank found that the average number of cars waiting during the noon hour at a drive-up window follows a Poisson distribution with a mean of 2 cars. Make a chart of this distribution and answer these questions concerning the probability of cars waiting at the drive-up window.\n",
    "\n",
    "    - What is the probability that no cars drive up in the noon hour?\n",
    "    - What is the probability that 3 or more cars come through the drive through?\n",
    "    - How likely is it that the drive through gets at least 1 car?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Poisson distribution $Î» = 1$')"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEXCAYAAAC3c9OwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYkUlEQVR4nO3debRlZX3m8e+TYlIGiVJqBMpCpTWYgNol4ixOYVBxmWgwBIdoCEtx6iZKaJZtJw7YHVtjC9Il4hQVEwUaGQQntBXQKrAoQMGuYCllgYACTgQo/fUfe1853HrvrXPh7ntr+H7WOuvus9/97v07p2qd5+zhvDtVhSRJk/3efBcgSdo4GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaE5kWSK5M8Y77raEny0SRv76dntc7R9SVZneTZQ6xbmg0GhO6V/kPutiS/TPKTJB9JssOG+lXVo6vqgjko8V4Zt85xP+xn63W3tjfke5rke0nWJHn0LK7zqCTLk9ye5KOztV7NHgNCs+H5VbUD8Djg8cBx81zPRifJVvNdw730R8D3gT+dxXWuBd4OnDKL69QsMiA0a6rqx8C5dB8mJPnDJBckuaU//PGCiWVHvwEneUuSHyf5RZKrkzxrZLlm2xjrPjrJyiS3JvlMku2mqjvJY5Nc2m/jM8B2k9b17JHn69WT5BPAIuDz/Z7Um0f6viXJSuBXSbZqfPN/fJLvJrm53/varu9bSR4xst3Rw17TbW/iPZ2196f/t/0N8A1gn+mWm4mqOq2qzgB+Olvr1OwyIDRrkuwOHAR8J8nWwOeB84EHAq8DPpnkkZP6PBI4Cnh8Ve0I/Amwerq2Mdf9EuAAYA9gb+AVU9S8DXAG8Ang/sC/MsW35KnqqarDgR/R70lV1X8f6fZS4GBg56pa11jtYf16Hg78B8bY+9rA9pjN92dknfcBDu2XbbWf1YdR63HWhl6TNk4GhGbDGUluofuG+TXgncB+wA7A8VV1R1V9BTiL7gNz1G+AbYG9kmxdVaur6t820DbOut9fVWur6md0H5aPmaL2/YCtgfdV1Z1V9Vlg2RTLTlfrVN5fVddW1W1TtH+gb/8Z8A7Wf3/uidl8fya8A/gx8PDWOaaqel5V7TzF43mz8Jo0DwwIzYYX9h8ED62q1/Qfhg8Brq2q344s90Ng19GOVbUKeCPwNuCGJKcmecgG2sZZ9/Uj07+m+8BseQjw47r7sMY/bC04Xa3TuHYG7T/s67m3ZvP9IckT6fY4/hS4lf4QojZ/BoSGshbYPcno/7FFdN9C76aqPlVVTwEeChTw7g20jb3uMVwH7Jokk9bVNE2tU42bv6Hx9HeftN21/fSvgfuOtD14BuudtfenPzdxCnBkv7dxGY3zEEnO7c+HtB7nznS72jgYEBrKt4BfAW9OsnW66/OfD5w6ulCSRyZ5ZpJtgX8HbqM7lDNd21jrHtNFwDrg9f1J5BcB+7YWnK5W4CfAw+7B9l+bZLck9weOBT7Tz18B/EWSBUkOAJ4+qd9025vN9+fvgYuqauI8wgoa5yGq6sD+fEjrcWBrxf37vR2wAFiQZLts+ld7bVYMCA2iqu4AXgAcCNwEnAi8rKqumrTotsDx/TLX051UPXa6thmse9w6X0R3kvZm4M+B06ZYfLpa3wUc15+UPXoGJXyK7mTyNf3j7f38N9B9qN9CdyL7jEn9ptzebL0/SfYFXgy8aWT2CmbvSqbj6EL2GOAv+2kvkd6IxDvKSZJa3IOQJDUZEJKkJgNCktRkQEiSmjarS8p22WWXWrx48XyXIUmbjEsuueSmqlrYatusAmLx4sUsX758vsuQpE1GkubIAeAhJknSFAwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpo2q19Sb6oWH3P24NtYffzBG922JW3c3IOQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUNGhAJDkgydVJViU5ptF+WJKV/ePCJPuMtK1OcnmSFUmWD1mnJGl9gw3Wl2QBcALwHGANsCzJmVX13ZHFfgA8vapuTnIgsBR4wkj7/lV101A1SpKmNuQexL7Aqqq6pqruAE4FDhldoKourKqb+6cXA7sNWI8kaQaGDIhdgWtHnq/p503lVcC5I88LOD/JJUmOGKA+SdI0hrwfRBrzqrlgsj9dQDxlZPaTq2ptkgcCX0xyVVV9vdH3COAIgEWLFt37qiVJwLB7EGuA3Uee7wasnbxQkr2Bk4FDquqnE/Oram3/9wbgdLpDVuupqqVVtaSqlixcuHAWy5ekLduQAbEM2DPJHkm2AQ4FzhxdIMki4DTg8Kr6/sj87ZPsODENPBe4YsBaJUmTDHaIqarWJTkKOA9YAJxSVVcmObJvPwl4K/AA4MQkAOuqagnwIOD0ft5WwKeq6gtD1SpJWt+g96SuqnOAcybNO2lk+tXAqxv9rgH2mTxfkjR3/CW1JKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUtOgAZHkgCRXJ1mV5JhG+2FJVvaPC5PsM25fSdKwBguIJAuAE4ADgb2AlybZa9JiPwCeXlV7A/8ALJ1BX0nSgIbcg9gXWFVV11TVHcCpwCGjC1TVhVV1c//0YmC3cftKkoY1ZEDsClw78nxNP28qrwLOnWnfJEckWZ5k+Y033ngvypUkjRoyINKYV80Fk/3pAuItM+1bVUuraklVLVm4cOE9KlSStL6tBlz3GmD3kee7AWsnL5Rkb+Bk4MCq+ulM+kqShjPkHsQyYM8keyTZBjgUOHN0gSSLgNOAw6vq+zPpK0ka1mB7EFW1LslRwHnAAuCUqroyyZF9+0nAW4EHACcmAVjXHy5q9h2qVknS+oY8xERVnQOcM2neSSPTrwZePW5fSdLc8ZfUkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkpkF/SS1NZ/ExZw++jdXHHzz4NqTNlXsQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoGDYgkByS5OsmqJMc02h+V5KIktyc5elLb6iSXJ1mRZPmQdUqS1rfVUCtOsgA4AXgOsAZYluTMqvruyGI/A14PvHCK1exfVTcNVaMkaWpjBUSS3YBDgacCDwFuA64AzgbOrarfNrrtC6yqqmv6dZwKHAL8LiCq6gbghiQH35sXIUmafRs8xJTkI8ApwB3Au4GXAq8BvgQcAHwjydMaXXcFrh15vqafN64Czk9ySZIjpqnviCTLkyy/8cYbZ7B6SdJ0xtmDeE9VXdGYfwVwWpJtgEWN9jTm1Qxqe3JVrU3yQOCLSa6qqq+vt8KqpcBSgCVLlsxk/ZKkaYxzknr1VA1JHl5Vd1TVqkbzGmD3kee7AWvHLayq1vZ/bwBOpztkJUmaI+MExGVJXjI6I8l2Sd4OfGGafsuAPZPs0e9lHAqcOU5RSbZPsuPENPBcuj0WSdIcGScgngu8MskXkzwiySHA5cC2wGOn6lRV64CjgPOA7wH/UlVXJjkyyZEASR6cZA3wn4DjkqxJshPwILpzG5cB3wbOrqrpwkiSNMs2eA6iqv4NODDJ3wJXAdcDf1JVV47R9xzgnEnzThqZvp7u0NNkPwf22dD6JUnDGecqpq2S/B3wN3RXLy0H3p/kkUMXJ0maP+McYvoO3eWp/7GqllbVC4H3Av8nyTuHLE6SNH/GCYhXVNVRVXXrxIyqOovu/IOXlUrSZmqcgLi0NbOqbquq/wKQpPWbB0nSJmycgPhqktcluduP4ZJsk+SZST4GvHyY8iRJ82WcX1IfAPwV8OkkewC3ANsBC4DzgfdW1YqhCpwri485e/BtrD7eIackbTrGucz134ETgROTbA3sAtxWVbcMXJskaR5tMCCSbAccCTwCWAmc0v8ITpK0GRvnHMTHgCV0v54+CHjPoBVJkjYK45yD2Kuq/hggyYfphr6QJG3mxtmDuHNiwkNLkrTlGGcPYp8kP++nA9ynfx6gqmqnwaqTJM2bca5iWjAXhUiSNi7jHGKSJG2BDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUNGhAJDkgydVJViU5ptH+qCQXJbk9ydEz6StJGtZgAZFkAXACcCCwF/DSJHtNWuxnwOuBf7wHfSVJAxpyD2JfYFVVXVNVdwCnAoeMLlBVN1TVMuDOmfaVJA1ryIDYFbh25Pmaft6s9k1yRJLlSZbfeOON96hQSdL6hgyINObVbPetqqVVtaSqlixcuHDs4iRJ0xsyINYAu4883w1YOwd9JUmzYMiAWAbsmWSPJNsAhwJnzkFfSdIs2GqoFVfVuiRHAecBC4BTqurKJEf27ScleTCwHNgJ+G2SNwJ7VdXPW32HqlWStL7BAgKgqs4Bzpk076SR6evpDh+N1VeSNHf8JbUkqcmAkCQ1DXqISdpYLT7m7MG3sfr4gwffhjQk9yAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpadCASHJAkquTrEpyTKM9Sd7ft69M8riRttVJLk+yIsnyIeuUJK1vq6FWnGQBcALwHGANsCzJmVX13ZHFDgT27B9PAD7Y/52wf1XdNFSNkqSpDbkHsS+wqqquqao7gFOBQyYtcwjw8epcDOyc5A8GrEmSNKYhA2JX4NqR52v6eeMuU8D5SS5JcsRgVUqSmgY7xASkMa9msMyTq2ptkgcCX0xyVVV9fb2NdOFxBMCiRYvuTb2SpBFD7kGsAXYfeb4bsHbcZapq4u8NwOl0h6zWU1VLq2pJVS1ZuHDhLJUuSRoyIJYBeybZI8k2wKHAmZOWORN4WX81037ArVV1XZLtk+wIkGR74LnAFQPWKkmaZLBDTFW1LslRwHnAAuCUqroyyZF9+0nAOcBBwCrg18Ar++4PAk5PMlHjp6rqC0PVKkla35DnIKiqc+hCYHTeSSPTBby20e8aYJ8ha5MkTc9fUkuSmgwISVKTASFJajIgJElNBoQkqWnQq5gkrW/xMWcPvo3Vxx88+Da0+XMPQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmrzlqLQF8Xanmgn3ICRJTQaEJKnJgJAkNRkQkqQmA0KS1DToVUxJDgD+CVgAnFxVx09qT99+EPBr4BVVdek4fSVtWryCatMz2B5EkgXACcCBwF7AS5PsNWmxA4E9+8cRwAdn0FeSNKAh9yD2BVZV1TUASU4FDgG+O7LMIcDHq6qAi5PsnOQPgMVj9JWksbj3cs8MGRC7AteOPF8DPGGMZXYdsy8ASY6g2/sA+GWSq+9FzTOxC3DTTDrk3QNVMrfb9nXP/bZnbJa3PaPX7uve5Dx0qoYhAyKNeTXmMuP07WZWLQWWzqy0ey/J8qpaMtfbnW++7i3Plvrat9TXPWrIgFgD7D7yfDdg7ZjLbDNGX0nSgIa8zHUZsGeSPZJsAxwKnDlpmTOBl6WzH3BrVV03Zl9J0oAG24OoqnVJjgLOo7tU9ZSqujLJkX37ScA5dJe4rqK7zPWV0/UdqtZ7aM4Pa20kfN1bni31tW+pr/t30l1AJEnS3flLaklSkwEhSWoyIO6BJAckuTrJqiTHzHc9cyHJ7km+muR7Sa5M8ob5rmkuJVmQ5DtJzprvWuZK/8PVzya5qv93f+J81zQXkryp/z9+RZJPJ9luvmuaLwbEDG3Bw4CsA/5zVf0hsB/w2i3kdU94A/C9+S5ijv0T8IWqehSwD1vA60+yK/B6YElV/RHdRTKHzm9V88eAmLnfDSFSVXcAE8OAbNaq6rqJgRSr6hd0Hxa7zm9VcyPJbsDBwMnzXctcSbIT8DTgwwBVdUdV3TKvRc2drYD7JNkKuC9b8G+wDIiZm2p4kC1GksXAY4FvzXMpc+V9wJuB385zHXPpYcCNwEf6Q2snJ9l+vosaWlX9GPhH4EfAdXS/zTp/fquaPwbEzI09DMjmKMkOwOeAN1bVz+e7nqEleR5wQ1VdMt+1zLGtgMcBH6yqxwK/Ajb7821Jfp/uiMAewEOA7ZP85fxWNX8MiJkbZwiRzVKSrenC4ZNVddp81zNHngy8IMlqusOJz0zyz/Nb0pxYA6ypqom9xM/SBcbm7tnAD6rqxqq6EzgNeNI81zRvDIiZ2yKHAelv7vRh4HtV9T/nu565UlV/V1W7VdViun/rr1TVZv+NsqquB65N8sh+1rPYMobb/xGwX5L79v/nn8UWcHJ+KoPeUW5ztIkMAzKEJwOHA5cnWdHPO7aqzpm/kjSw1wGf7L8IXUM/FM7mrKq+leSzwKV0V+59hy14yA2H2pAkNXmISZLUZEBIkpoMCElSkwEhSWoyICRJTQaEBpWkkrxn5PnRSd42C+vdNsmXkqxI8ueN9qP7UUivSHJZkpfd221OWv/pSV448vzqJMeNPP9ckhdN0//kicEOkxw7qe3C2ay1se3FSf5imrZK8rqReR9I8ooha9LGyYDQ0G4HXpRkl1le72OBravqMVX1mdGG/ra2zwH27UfkfBrtIVKa+kHaNuRC+l/YJnkA8EtgdDjsJ/bLNFXVq6tq4odnx05qG/qXu4uBZkD0bgDe0P/+QVswA0JDW0f3Q6M3TW5I8tAkX06ysv+7qLHM/ZOc0S9zcZK9kzwQ+GfgMf0exMMndTsWeM3EWFFVdWtVfaxf31uTLOv3LJb2v5YlyQVJ3pnka3Qfji8e2fv4euN1fZO7hmB4EnAWsDCdPYDbqur6JB9Msry/v8B/G3ldFyRZkuR4upFDVyT5ZN/2y/7vM/rlJu7J8MmReg/q530jyfvTuE9Fvzfwf5Nc2j8m6j0eeGq/zfX+XegG6fsy8PLGOh/T/zus7Peifn8D8y9I8u4k307y/SRPbWxPG6uq8uFjsAfdN+udgNXA/YCjgbf1bZ8HXt5P/xVwRqP//wL+az/9TGBFP/0M4KzG8jsCN09Tz/1Hpj8BPL+fvgA4caTtcmDXfnrnxnq2BW4BtgHeBRzQr28v4DDg46Pbo/vV/QXA3iPbWzLxHk1+z0Ze46104339HnAR8BRgO7oRhffol/v0FO/FfYHt+uk9geXTvXd922LgCrrB6q7q6/4A8Iq+fSXw9H7674H3bWD+BcB7+umDgC/N9/9JH+M/3IPQ4Kr7Jv9xuhuxjHoi8Kl++hN0H36TPaVvo6q+Ajwgyf2m2VyYfnTd/ZN8K8nldIHz6JG20UNV3wQ+muSv6T4k76aqbgeupBvAbj+6oc8votubeBJ3HV56SZJL6YZseDRdgMzEt6tqTVX9FlhB9wH+KOCaqvpBv8ynp+i7NfCh/rX+60y23a/724wciurf952r6mv9rI8BT5tq/sjqJgZ2vKSvX5sIA0Jz5X3Aq4Dp7inQ+mCf0fDqfRj9KsnD1ltRd+vIE4E/q6o/Bj5E9218wq9G1nMkcBzdyL0r+vMMk11I90G4Y1XdDFzMXQHxzf5Q09HAs6pqb+DsSdsbx+0j07+hGz9t3PMpbwJ+Qnc3uCV0ezsz8U7gLdz7z4mJ1zBRvzYRBoTmRFX9DPgXupCYcCF33c7xMOAbja5f79tI8gzgptrwfSjeBZyQ7q5oJNkpyRHc9eF8U7r7WvzZVCtI8vCq+lZVvRW4ibsP8T7hm8DfAJf1z1fS7U0sotu72IkudG5N8iC629S23JluKPVxXQU8LN2NmwDWu4qrdz/gun7v43Du2hP6Bd2huGlV1VV0I7g+r39+K3DzyHmEw4GvTTV/Bq9HGynTXHPpPcBRI89fD5yS5G/pToy2Rgt9G91dzVYCv6Zx4rThg8AOwLIkdwJ30h0HvyXJh+jOL6ymG7p9Kv8jyZ5039a/zF0hMOpCujuvvQt+N9LvDcC1/YfyZUm+QxcW19AFSstSYGWSS6vqsA29uKq6LclrgC8kuYnuUFDLicDnkrwY+Cp37SGtBNYluQz4aFW9d5rNvYPu8NiElwMnJbkvdx/hdar52oQ5mqu0CUqyQ1X9sr+q6QTg/23gg16aMQ8xSZumv053X44r6Q4l/e/5LUebI/cgJElN7kFIkpoMCElSkwEhSWoyICRJTQaEJKnp/wOTnapwB6vfaQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Î» = 2\n",
    "\n",
    "x = np.arange(0,10)\n",
    "y = stats.poisson(Î»).pmf(x)\n",
    "\n",
    "plt.bar(x,y)\n",
    "plt.xlabel('No of Cars Waiting at Noon')\n",
    "plt.ylabel('P(X)')\n",
    "plt.title('Poisson distribution $Î» = 1$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1b. What is the probability that no cars drive up in the noon hour?\n",
    "\n",
    "# 14% probability that no cars drive up in the noon hour\n",
    "stats.poisson(Î»).pmf(0).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1c. What is the probability that 3 or more cars come through the drive through?\n",
    "\n",
    "# 32% probability that 3 or more cars come through the drive-thru\n",
    "lambda_of_cars = stats.poisson(Î»)\n",
    "lambda_of_cars.sf(2).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1d. How likely is it that the drive through gets at least 1 car?\n",
    "# 86% probability that the drive thru sees at least 1 or more cars\n",
    "\n",
    "lambda_of_cars.sf(0).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grades of State University graduates are normally distributed with a mean of 3.0 and a standard deviation of .3. Calculate the following:\n",
    "\n",
    "    - What grade point average is required to be in the top 5% of the graduating class?\n",
    "    - What GPA constitutes the bottom 15% of the class?\n",
    "    - An eccentric alumnus left scholarship money for students in the third decile from the bottom of their class\n",
    "    - Determine the range of the third decile\n",
    "    - Would a student with a 2.8 grade point average qualify for this scholarship?\n",
    "    - If I have a GPA of 3.5, what percentile am I in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. \n",
    "\n",
    "mean = 3\n",
    "std_dev = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.49"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2a. What grade point average is required to be in the top 5% of the graduating class?\n",
    "\n",
    "# 3.49 GPA = top 5% of class\n",
    "university = stats.norm(mean, std_dev)\n",
    "university.isf(0.05).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.69"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2b. What GPA constitutes the bottom 15% of the class?\n",
    "\n",
    "# 2.69 GPA\n",
    "university.ppf(0.15).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  2d. An eccentric alumnus left scholarship money for students in the third decile from the bottom of their class. \n",
    "# Determine the range of the third decile.\n",
    "# 3rd Decile from Bottom is in range of 2.75 - 2.84 GPA\n",
    "\n",
    "# Would a student with a 2.8 grade point average qualify for this scholarship?\n",
    "# Yes, a 2.8 GPA would qualify for this scholarship\n",
    "\n",
    "bottom_10 = university.ppf(.1) # 2.62 GPA represents the top 10% of class\n",
    "top_10 = university.isf(.1) # 3.38 GPA represents the top 10% of class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.74751363, 2.84267985])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "university.ppf((0.2, 0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.441677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.581257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.720838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.860419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3.139581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.279162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.418743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.558323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  2.441677\n",
       "1  2.581257\n",
       "2  2.720838\n",
       "3  2.860419\n",
       "4  3.000000\n",
       "5  3.139581\n",
       "6  3.279162\n",
       "7  3.418743\n",
       "8  3.558323"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# attempting to use numpy's \"percentile\" method to calculate decile\n",
    "\n",
    "top_1 = university.isf(0.01)\n",
    "bottom_1 = university.ppf(0.01)\n",
    "\n",
    "uni_array = np.array([bottom_1, top_1])\n",
    "uni_percentiles = np.percentile(uni_array, np.arange(10, 100, 10))\n",
    "percentiles_df = pd.DataFrame(uni_percentiles)\n",
    "percentiles_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    3.384465\n",
       "9     3.307572\n",
       "8     3.230679\n",
       "7     3.153786\n",
       "6     3.076893\n",
       "5     3.000000\n",
       "4     2.923107\n",
       "3     2.846214\n",
       "2     2.769321\n",
       "1     2.692428\n",
       "0     2.615535\n",
       "Name: 0, dtype: float64"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"percentile\" approach -- probably not correct? ***\n",
    "\n",
    "var = np.array([bottom_10, top_10])\n",
    "quantiles = np.percentile(var, np.arange(0, 101, 10))\n",
    "quantile_df = pd.DataFrame(quantiles)\n",
    "quantile_df = quantile_df[0][::-1] # reversing the order of the column, placing highest quantile first in the order\n",
    "\n",
    "quantile_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.95"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2e. If I have a GPA of 3.5, what percentile am I in?\n",
    "\n",
    "# 95% percentile\n",
    "university.cdf(3.5).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem #3 A marketing website has...\n",
    "    - an average click-through rate of 2%\n",
    "    - One day they observe 4326 visitors and 97 click-throughs\n",
    "    - How likely is it that this many people or more click through?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. binomial distribution\n",
    "\n",
    "# How likely is it that this many people or more click through?\n",
    "# 14% probability that there are 97 or more click throughs given the 4326 number of visitors \n",
    "\n",
    "n_trials = 4326\n",
    "p = 0.02\n",
    "\n",
    "clicks = stats.binom(n_trials, p)\n",
    "clicks.sf(96).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. You are working on some statistics homework consisting of 100 questions where all of the answers are a probability rounded to the hundreths place. \n",
    "# Looking to save time, you put down random probabilities as the answer to each question.\n",
    "\n",
    "n_questions = 100\n",
    "p_questions = 0.50\n",
    "\n",
    "test = stats.binom(n_questions, p_questions)\n",
    "\n",
    "test.cdf(60).round(2)\n",
    "\n",
    "# What is the probability that at least one of your first 60 answers is correct?\n",
    "# 98% probability that at least one out of the first 60 questions / answers will be correct\n",
    "\n",
    "# Binomial Distribution --> where there is a \"correct\" and \"incorrect\" answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (class walk-thru)\n",
    "\n",
    "stats.binom(60, 0.01).sf(0).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials = 10_000\n",
    "n_questions = 100\n",
    "p_questions = 0.50\n",
    "\n",
    "test = np.random.choice([0, 1], size=(n_trials, n_questions), p = [p_questions, p_questions])\n",
    "\n",
    "(test[:61].sum(axis=1) >= 1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_trials = 10_000\n",
    "n_questions = 100\n",
    "p_questions = 0.50\n",
    "\n",
    "test = np.random.choice([0, 1], size=(n_trials, n_questions), p = [p_questions, p_questions])\n",
    "\n",
    "test_df = pd.DataFrame(test)\n",
    "\n",
    "(test_df.iloc[:,range(0, 61)].sum(axis=1) >= 1).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### The codeup staff tends to get upset when the student break area is not cleaned up. \n",
    " \n",
    "    - Suppose that there's a 3% chance that any one student cleans the break area when they visit it, and, on any given day... \n",
    "    - About 90% of the 3 active cohorts of 22 students visit the break area\n",
    "    - How likely is it that the break area gets cleaned up each day? \n",
    "    - How likely is it that it goes two days without getting cleaned up? \n",
    "    - All week?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (class walk-thru)\n",
    "# chance that break-room gets cleaned up at least 1 once daily\n",
    "# where 90% of 3 cohorts of 22 = 59 students daily \n",
    "\n",
    "stats.binom(59, 0.03).sf(0).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  5a.  How likely is it that the break area gets cleaned up each day? \n",
    "# 84% chance that the break room is cleaned-up every day\n",
    "\n",
    "n_trials = 10_000\n",
    "p = 0.03\n",
    "\n",
    "# where \"0\" represents \"doesn't clean\" and \"1\" represents \"cleans\"\n",
    "cleanup = np.random.choice([0, 1], size=(n_trials, 59), p=[0.97, 0.03])\n",
    "(cleanup.sum(axis=1) >= 1).mean().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.31"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  5b.  How likely is it that it goes two days without getting cleaned? \n",
    "# 31% probability that the breakroom goes two (2) without being cleaned\n",
    "\n",
    "n_trials = 10_000\n",
    "p = 0.03 # probability that 1 out of the students who visit the break-room will clean\n",
    "\n",
    "# what am I given to work with?\n",
    "# probability that someone cleans (probability)\n",
    "# percent of students who visit the break room (value)\n",
    "\n",
    "## this problem can also be expressed as a \"binomial distribution\" \"cleans or doesn't clean\"\n",
    "## note: that you will also have twice (2) as many students visiting the break room\n",
    "# 59 * 2 = 118 students\n",
    "\n",
    "\n",
    "stats.binom(118, 0.03).cdf(2).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5c.  How likely is it that it goes the entire week without getting cleaned? \n",
    "# 2% probability that the break room goes 1 week without being cleaned\n",
    "\n",
    "stats.binom(395, 0.03).cdf(5).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. You want to get lunch at La Panaderia, but notice that the line is usually very long at lunchtime. \n",
    "\n",
    "    - After several weeks of careful observation, you notice that the average number of people in line when your lunch break starts is normally distributed with a mean of 15 and standard deviation of 3. \n",
    "    \n",
    "    - If it takes 2 minutes for each person to order, and 10 minutes from ordering to getting your food, what is the likelihood that you have at least 15 minutes left to eat your food before you have to go back to class? \n",
    "    \n",
    "    - Assume you have one hour for lunch, and ignore travel time to and from La Panaderia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7976716190363569"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. what is the likelihood that you have at least 15 minutes left to eat your food before you have to go back to class? \n",
    "\n",
    "# 63% probability that you will have at least 15 minutes left to eat\n",
    "\n",
    "\n",
    "# \"what am I given?\"\n",
    "# mean_in_line = 15 people\n",
    "# std_dev of people = 3\n",
    "# time it takes to order = 2mins\n",
    "# time it takes to get food = 10 mins\n",
    "# lunch break = 1 hour\n",
    "\n",
    "# the problem/question can be set-up as a \"normal distribution\"\n",
    "\n",
    "mean = 15\n",
    "std_dev = 3\n",
    "\n",
    "lunch = stats.norm(mean, std_dev)\n",
    "\n",
    "# next, i'll want to calculate the average time it takes someone to order, receive their food, and have 15 minutes remaining within an hour\n",
    "\n",
    "fifteen_mins_remaining = (60 - 15 - 10) / 2 # diving by \"2\" to denote that everyone in line take 2minutes \n",
    "fifteen_mins_remaining # \"contineous value\" of 17.5 or...\n",
    "# 17.5 minutes it would need to take someone to \n",
    "# 1. wait in line, \n",
    "# 2. order their food, \n",
    "# 3. wait for their food, and...\n",
    "# 4. have 15 minutes remaining to eat their food\n",
    "\n",
    "lunch.cdf(fifteen_mins_remaining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (class walk-thru) of above exercise\n",
    "# (15, 3) and 16 people (including myself waiting in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to SQL employee database\n",
    "# np.diff(salary_norm.cdf([65_000, 80_000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem #4: Connect to the employees database and find the average salary of current employees, along with the standard deviation. \n",
    "\n",
    "    For the following questions, calculate the answer based on modeling the employees salaries with a normal distribution defined by the calculated mean and standard deviation \n",
    "    then compare this answer to the actual values present in the salaries dataset.\n",
    "\n",
    "- What percent of employees earn less than 60,000?\n",
    "- What percent of employees earn more than 95,000?\n",
    "- What percent of employees earn between 65,000 and 80,000?\n",
    "- What do the top 5% of employees make?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tables_in_employees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>departments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dept_emp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dept_manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>employees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>salaries</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>titles</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Tables_in_employees\n",
       "0         departments\n",
       "1            dept_emp\n",
       "2        dept_manager\n",
       "3           employees\n",
       "4            salaries\n",
       "5              titles"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the enviorment and connecting to MySQL database\n",
    "\n",
    "from env import user, password, host, get_db_url\n",
    "url = get_db_url(user, password, host, \"employees\")\n",
    "\n",
    "# I want to now show all tables within the \"employees\" MySQL database\n",
    "# I can run the following code to do so:\n",
    "\n",
    "employees_db_tables = pd.read_sql(\"SHOW TABLES\", url)\n",
    "employees_db_tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I now see the \"salaries\" table that I will want to work with\n",
    "# Therefore, I can create a new \"dataframe\" of the Salaries Table with the following code:\n",
    "\n",
    "salaries_table = pd.read_sql(\"SELECT * FROM salaries\", url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emp_no</th>\n",
       "      <th>salary</th>\n",
       "      <th>from_date</th>\n",
       "      <th>to_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10001</td>\n",
       "      <td>60117</td>\n",
       "      <td>1986-06-26</td>\n",
       "      <td>1987-06-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10001</td>\n",
       "      <td>62102</td>\n",
       "      <td>1987-06-26</td>\n",
       "      <td>1988-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10001</td>\n",
       "      <td>66074</td>\n",
       "      <td>1988-06-25</td>\n",
       "      <td>1989-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10001</td>\n",
       "      <td>66596</td>\n",
       "      <td>1989-06-25</td>\n",
       "      <td>1990-06-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10001</td>\n",
       "      <td>66961</td>\n",
       "      <td>1990-06-25</td>\n",
       "      <td>1991-06-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   emp_no  salary   from_date     to_date\n",
       "0   10001   60117  1986-06-26  1987-06-26\n",
       "1   10001   62102  1987-06-26  1988-06-25\n",
       "2   10001   66074  1988-06-25  1989-06-25\n",
       "3   10001   66596  1989-06-25  1990-06-25\n",
       "4   10001   66961  1990-06-25  1991-06-25"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running the following code to show the contents of the salaries table/dataframe\n",
    "salaries_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999-01-01    240124\n",
       "1998-10-25      1034\n",
       "1997-10-26       872\n",
       "2002-04-03       821\n",
       "2000-08-26       815\n",
       "               ...  \n",
       "1985-08-29         1\n",
       "1985-06-15         1\n",
       "1986-01-14         1\n",
       "1985-12-08         1\n",
       "1985-11-17         1\n",
       "Name: to_date, Length: 6120, dtype: int64"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# i now want to create a new table for just \"current employees\"\n",
    "# i can do this by specifying the \"to_date\" column and quering for dates greater than \"today\"\n",
    "# as a good practice, i first want to see the \"unique values\" within this column \n",
    "# alternatively, i could convert all date columns to datetime types and run a operand \">\" today\n",
    "\n",
    "salaries_table.dtypes\n",
    "salaries_table.to_date.value_counts() # here i can see that \"9999-01-01\" is the \"current date\" identifier for this table / company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering for current employee salaries only\n",
    "import datetime # importing \"datetime\" here to help filter for current dates\n",
    "salaries_table['is_current'] = salaries_table['to_date'] == datetime.date(9999, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_no       240124\n",
       "salary       240124\n",
       "from_date    240124\n",
       "to_date      240124\n",
       "dtype: int64"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (class walkthrough) approach\n",
    "# using the filtering in the SQL query \n",
    "# nice approach \n",
    "# question / feedback - yet, in instances where you may need both current and past salaries\n",
    "# would it be good to instead just pull the entire table and filter for what you're analyzing through pandas/python? (like my approach)\n",
    "\n",
    "\n",
    "query = '''\n",
    "SELECT * \n",
    "FROM salaries \n",
    "WHERE salaries.to_date > NOW()\n",
    "'''\n",
    "\n",
    "df1 = pd.read_sql(query, url)\n",
    "df1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_salaries = salaries_table[salaries_table['is_current'] == True] # checking that only current employees salaries are present\n",
    "# calculating the mean salary for current employees\n",
    "\n",
    "round(current_salaries.salary.mean(), 2)\n",
    "salary_mean = 72012.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating salary standard deviation \n",
    "round(current_salaries.salary.std(), 2)\n",
    "salary_std = 17310.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now i can create a normal distribution for the current salaries\n",
    "salary_distribution = stats.norm(salary_mean, salary_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0% of employees are earning less than $60,000.\n"
     ]
    }
   ],
   "source": [
    "#  What percent of employees earn less than 60,000?\n",
    "\n",
    "print(f'{salary_distribution.cdf(59999).round(2)*100}% of employees are earning less than $60,000.') # since CDF is \"inclusive\" of the input number and i want less than 60K, it should be ~59999K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0% of employees are earning more than $95,000.\n"
     ]
    }
   ],
   "source": [
    "# What percent of employees earn more than 95,000?\n",
    "\n",
    "# since the question calls for \"more than\" 95k and the \"sf()\" survival function is exclusive of the input number, i can include 95K which will not be captured\n",
    "print(f'{salary_distribution.sf(95000).round(2)*100}% of employees are earning more than $95,000.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.5% of employees are earning between $65,000 and $80,000.\n"
     ]
    }
   ],
   "source": [
    "# What percent of employees earn between 65,000 and 80,000?\n",
    "\n",
    "print(f'{(salary_distribution.cdf(80000) - salary_distribution.cdf(65000)).round(3)*100}% of employees are earning between $65,000 and $80,000.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 5% of employees earn a minimum of $100484.66\n"
     ]
    }
   ],
   "source": [
    "# What do the top 5% of employees make?\n",
    "print(f\"The top 5% of employees earn a minimum of ${salary_distribution.isf(0.05).round(2)}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
